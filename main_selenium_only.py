#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Amazon Japan å–å®¶ä¿¡æ¯æå–å·¥å…· - çº¯Seleniumç‰ˆ v5.0
ç»ˆææ–¹æ¡ˆï¼šå®Œå…¨ä½¿ç”¨æ— å¤´æµè§ˆå™¨ï¼Œç»•è¿‡æ‰€æœ‰åçˆ¬è™«é™åˆ¶
"""

import tkinter as tk
from tkinter import ttk, messagebox
from bs4 import BeautifulSoup
import pandas as pd
import time
import random
import re
import threading
import os
from datetime import datetime
from urllib.parse import urljoin

try:
    import undetected_chromedriver as uc
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    SELENIUM_OK = True
except:
    SELENIUM_OK = False


class SeleniumOnlyScraper:
    """çº¯Seleniumçˆ¬è™« - ç»ˆææ–¹æ¡ˆ"""
    
    def __init__(self):
        self.base_url = "https://www.amazon.co.jp"
        self.is_searching = False
        self.save_directory = "amazon_data"
        os.makedirs(self.save_directory, exist_ok=True)
    
    def search_products(self, keyword, max_pages=5, max_products=100,
                       progress_callback=None, stop_flag=None):
        """ä½¿ç”¨Seleniumæœç´¢äº§å“å’Œå–å®¶ä¿¡æ¯"""
        if not SELENIUM_OK:
            if progress_callback:
                progress_callback("âŒ Seleniumæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install selenium undetected-chromedriver")
            return [], []
        
        self.is_searching = True
        all_products = []
        all_sellers = []
        driver = None
        
        try:
            if progress_callback:
                progress_callback("ğŸš€ å¯åŠ¨æ— å¤´æµè§ˆå™¨...")
            
            # åˆ›å»ºæ— å¤´æµè§ˆå™¨
            options = uc.ChromeOptions()
            options.add_argument('--headless=new')
            options.add_argument('--disable-gpu')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--lang=ja-JP')
            
            driver = uc.Chrome(options=options)
            driver.set_page_load_timeout(30)
            
            if progress_callback:
                progress_callback("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
            
            # æœç´¢æ¯ä¸€é¡µ
            for page in range(1, max_pages + 1):
                if stop_flag and not stop_flag():
                    break
                
                if progress_callback:
                    progress_callback(f"ğŸ” æœç´¢ç¬¬ {page}/{max_pages} é¡µ...")
                
                try:
                    # è®¿é—®æœç´¢é¡µ
                    search_url = f"{self.base_url}/s?k={keyword}&page={page}"
                    driver.get(search_url)
                    
                    # ç­‰å¾…åŠ è½½
                    try:
                        WebDriverWait(driver, 15).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, 'div[data-component-type="s-search-result"]'))
                        )
                    except:
                        if progress_callback:
                            progress_callback(f"âš ï¸ ç¬¬{page}é¡µåŠ è½½è¶…æ—¶")
                        continue
                    
                    # è§£æäº§å“ - ç›´æ¥ç”¨BeautifulSoupè§£æå®Œæ•´é¡µé¢
                    soup = BeautifulSoup(driver.page_source, 'html.parser')
                    items = soup.select('div[data-component-type="s-search-result"]')
                    
                    if not items:
                        if progress_callback:
                            progress_callback(f"âš ï¸ ç¬¬{page}é¡µæ— äº§å“")
                        continue
                    
                    if progress_callback:
                        progress_callback(f"ğŸ“¦ ç¬¬{page}é¡µæ‰¾åˆ°{len(items)}ä¸ªäº§å“")
                    
                    # æå–æ¯ä¸ªäº§å“ - itemså·²ç»æ˜¯BeautifulSoupå¯¹è±¡
                    for idx, item in enumerate(items, 1):
                        if stop_flag and not stop_flag():
                            break
                        
                        if len(all_products) >= max_products:
                            break
                        
                        try:
                            # itemå·²ç»æ˜¯BeautifulSoupçš„Tagå¯¹è±¡ï¼Œç›´æ¥æå–
                            product = self._extract_product(item)
                            if not product or not product.get('url'):
                                continue
                            
                            if progress_callback:
                                progress_callback(f"ğŸ“‹ [{len(all_products)+1}/{max_products}] {product['title'][:30]}...")
                            
                            all_products.append(product)
                            
                            # è·å–å–å®¶ä¿¡æ¯
                            if product['url']:
                                seller = self._get_seller_with_browser(driver, product, progress_callback)
                                if seller:
                                    all_sellers.append(seller)
                            
                            # å»¶è¿Ÿ
                            time.sleep(random.uniform(0.5, 1.0))
                            
                        except Exception as e:
                            if progress_callback:
                                progress_callback(f"âš ï¸ äº§å“å¤„ç†å¤±è´¥: {e}")
                    
                    if len(all_products) >= max_products:
                        break
                    
                    # é¡µé¢é—´å»¶è¿Ÿ
                    time.sleep(random.uniform(2, 3))
                    
                except Exception as e:
                    if progress_callback:
                        progress_callback(f"âŒ ç¬¬{page}é¡µå‡ºé”™: {e}")
            
            # ä¿å­˜ç»“æœ
            if all_products:
                filename = self._save_to_excel(all_products, all_sellers)
                if progress_callback:
                    progress_callback(f"ğŸ’¾ å·²ä¿å­˜åˆ°: {filename}")
                    progress_callback(f"âœ… å®Œæˆï¼äº§å“:{len(all_products)}, å–å®¶:{len(all_sellers)}")
            else:
                if progress_callback:
                    progress_callback("âŒ æœªè·å–åˆ°ä»»ä½•äº§å“")
            
            return all_products, all_sellers
            
        except Exception as e:
            if progress_callback:
                progress_callback(f"âŒ ä¸¥é‡é”™è¯¯: {e}")
            return all_products, all_sellers
        finally:
            if driver:
                try:
                    driver.quit()
                    if progress_callback:
                        progress_callback("ğŸ”’ æµè§ˆå™¨å·²å…³é—­")
                except:
                    pass
            self.is_searching = False
    
    def _extract_product(self, element):
        """æå–äº§å“ä¿¡æ¯"""
        try:
            asin = element.get('data-asin', '')
            if not asin or len(asin) < 5:
                return None
            
            # ç›´æ¥ç”¨ASINæ„å»ºURLï¼ˆæœ€å¯é ï¼‰
            url = f"{self.base_url}/dp/{asin}"
            
            # æ ‡é¢˜ - å°è¯•å¤šç§é€‰æ‹©å™¨
            title = ''
            h2 = element.select_one('h2')
            if h2:
                # è·å–h2ä¸‹æ‰€æœ‰æ–‡æœ¬
                title = h2.get_text(strip=True)
            
            if not title or len(title) < 10:
                # å¤‡ç”¨æ–¹æ¡ˆ
                for selector in ['.a-size-medium', '.a-size-base-plus', 'span.a-text-normal']:
                    elem = element.select_one(selector)
                    if elem:
                        title = elem.get_text(strip=True)
                        if len(title) > 10:
                            break
            
            if not title or len(title) < 5:
                return None
            
            # ä»·æ ¼
            price = 'ä»·æ ¼æœªçŸ¥'
            price_elem = element.select_one('.a-price .a-offscreen')
            if price_elem:
                price = price_elem.get_text(strip=True)
            else:
                price_whole = element.select_one('.a-price-whole')
                if price_whole:
                    price = price_whole.get_text(strip=True)
            
            # è¯„åˆ†
            rating = ''
            rating_elem = element.select_one('.a-icon-alt')
            if rating_elem:
                rating = rating_elem.get_text(strip=True)
            
            return {
                'asin': asin,
                'title': title[:150],
                'price': price,
                'rating': rating,
                'url': url,
            }
        except Exception as e:
            print(f"æå–äº§å“å¤±è´¥: {e}")
            return None
    
    def _get_seller_with_browser(self, driver, product, progress_callback):
        """ä½¿ç”¨æµè§ˆå™¨è·å–å–å®¶ä¿¡æ¯"""
        try:
            # è®¿é—®äº§å“é¡µ
            driver.get(product['url'])
            
            # ç­‰å¾…é¡µé¢åŠ è½½
            try:
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, '#merchant-info, #buybox, #tabular-buybox, #availability'))
                )
            except:
                pass
            
            time.sleep(1)
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            
            # æå–å–å®¶åç§°å’Œé“¾æ¥
            seller_name = 'æœªçŸ¥å–å®¶'
            seller_url = ''
            
            # æ–¹æ³•1: merchant-infoåŒºåŸŸï¼ˆæœ€å¸¸è§ï¼‰
            merchant_info = soup.select_one('#merchant-info')
            if merchant_info:
                link = merchant_info.select_one('a[href*="seller="], a[href*="/sp?"], a[href*="/shops/"]')
                if link:
                    seller_name = link.get_text(strip=True)
                    seller_url = urljoin(self.base_url, link.get('href'))
            
            # æ–¹æ³•2: tabular-buyboxåŒºåŸŸ
            if seller_name == 'æœªçŸ¥å–å®¶':
                tabular = soup.select_one('#tabular-buybox')
                if tabular:
                    # æŸ¥æ‰¾"é…é€æ–¹"æ ‡ç­¾
                    seller_row = None
                    for span in tabular.find_all('span', string=re.compile(r'é…é€æ–¹|è²©å£²å…ƒ|å‡ºå“è€…|Sold by')):
                        seller_row = span.find_parent('div', class_=re.compile(r'tabular'))
                        if seller_row:
                            break
                    
                    if seller_row:
                        link = seller_row.select_one('a[href*="seller="], a[href*="/sp?"]')
                        if link:
                            seller_name = link.get_text(strip=True)
                            seller_url = urljoin(self.base_url, link.get('href'))
            
            # æ–¹æ³•3: ç›´æ¥æœç´¢"é…é€æ–¹"æ–‡æœ¬
            if seller_name == 'æœªçŸ¥å–å®¶':
                text = soup.get_text()
                # æŸ¥æ‰¾"é…é€æ–¹ Amazon" æˆ– "é…é€æ–¹ SENNWAK ç›´å–¶åº—"è¿™æ ·çš„æ¨¡å¼
                seller_match = re.search(r'é…é€æ–¹[ï¼š:\s]+([^\n\r]{2,50})', text)
                if seller_match:
                    seller_name = seller_match.group(1).strip()
                    # å°è¯•æ‰¾åˆ°å¯¹åº”çš„é“¾æ¥
                    for link in soup.find_all('a', href=re.compile(r'/sp\?|seller=')):
                        link_text = link.get_text(strip=True)
                        if link_text and link_text in seller_name:
                            seller_url = urljoin(self.base_url, link.get('href'))
                            break
            
            # æ–¹æ³•4: ç›´æ¥æŸ¥æ‰¾æ‰€æœ‰seller=é“¾æ¥ï¼ˆæœ€é€šç”¨ï¼‰
            if seller_name == 'æœªçŸ¥å–å®¶':
                seller_links = soup.find_all('a', href=re.compile(r'seller='))
                if seller_links:
                    # ä¼˜å…ˆé€‰æ‹©å¸¦æœ‰åº—é“ºåç§°çš„é“¾æ¥
                    for link in seller_links:
                        text = link.get_text(strip=True)
                        href = link.get('href')
                        # è¿‡æ»¤æ‰ç©ºæ–‡æœ¬å’Œæ— å…³é“¾æ¥
                        if text and len(text) > 2 and len(text) < 100:
                            # æ’é™¤ä¸€äº›å¸¸è§çš„æ— å…³æ–‡æœ¬
                            if text not in ['è©³ç´°', 'è©³ç´°ã‚’è¦‹ã‚‹', 'View details', 'More', 'Learn more']:
                                seller_name = text
                                seller_url = urljoin(self.base_url, href)
                                break
            
            if progress_callback:
                progress_callback(f"   ğŸª å–å®¶: {seller_name}")
            
            seller_info = {
                'seller_name': seller_name,
                'seller_url': seller_url,
                'phone': '',
                'address': '',
                'business_name': '',
                'email': '',
                'fax': '',
                'product_title': product['title'],
                'product_price': product['price'],
                'product_url': product['url'],
                'product_asin': product['asin'],
            }
            
            # å¦‚æœæœ‰å–å®¶é“¾æ¥ä¸”ä¸æ˜¯Amazonï¼Œè·å–è¯¦ç»†ä¿¡æ¯
            if seller_url and 'amazon' not in seller_name.lower():
                time.sleep(random.uniform(1.5, 2.5))
                details = self._get_seller_details_with_browser(driver, seller_url)
                seller_info.update(details)
            
            return seller_info
        except Exception as e:
            if progress_callback:
                progress_callback(f"   âš ï¸ å–å®¶ä¿¡æ¯è·å–å¤±è´¥: {e}")
            return None
    
    def _get_seller_details_with_browser(self, driver, seller_url):
        """ä½¿ç”¨æµè§ˆå™¨è·å–å–å®¶è¯¦ç»†ä¿¡æ¯ - æ ¹æ®Amazonæ—¥æœ¬å–å®¶é¡µé¢ç»“æ„"""
        try:
            driver.get(seller_url)
            
            # ç­‰å¾…è¯¦ç»†ä¿¡æ¯åŠ è½½
            try:
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, 'body'))
                )
            except:
                pass
            
            time.sleep(2)
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            text = soup.get_text()
            
            details = {}
            
            # Business Name (äº‹æ¥­è€…å) - ä»"è¯¦å°½çš„å–å®¶ä¿¡æ¯"åŒºåŸŸæå–
            business_patterns = [
                r'Business Name[ï¼š:\s]*([^P\n]{3,100})(?:Phone|TEL|ç”µè¯)',  # åŒ¹é…åˆ°Phoneä¹‹å‰
                r'äº‹æ¥­è€…å[ï¼š:\s]*([^\n]{3,100})',
                r'ä¼šç¤¾å[ï¼š:\s]*([^\n]{3,100})',
                r'è²©å£²æ¥­è€…[ï¼š:\s]*([^\n]{3,100})',
            ]
            for pattern in business_patterns:
                match = re.search(pattern, text)
                if match:
                    biz_name = match.group(1).strip()
                    # æ¸…ç†å¯èƒ½çš„æ¢è¡Œå’Œå¤šä½™ç©ºæ ¼
                    biz_name = re.sub(r'\s+', ' ', biz_name)
                    details['business_name'] = biz_name
                    break
            
            # Phone (å’¨è¯¢ç”¨ç”µè¯å·ç ) - ä¼˜å…ˆåŒ¹é…æ ‡ç­¾åçš„æ•°å­—
            phone_patterns = [
                r'Phone Number[ï¼š:\s]*(\d{10,15})',
                r'å’¨è¯¢ç”¨ç”µè¯å·ç [ï¼š:\s]*(\d{10,15})',
                r'é›»è©±ç•ªå·[ï¼š:\s]*(\d{10,15})',
                r'TEL[ï¼š:\s]*(\d{10,15})',
                r'ç”µè¯[ï¼š:\s]*(\d{10,15})',
                r'Tel[ï¼š:\s]*(\d{10,15})',
                # åŒ¹é…ç‹¬ç«‹çš„11ä½æ•°å­—ï¼ˆä¸­å›½æ‰‹æœºå·ï¼‰
                r'(?:^|\n|\s)(\d{11})(?:\n|\s|Address|åœ°å€)',
                # åŒ¹é…æ—¥æœ¬ç”µè¯å·ç æ ¼å¼ï¼ˆå¸¦è¿å­—ç¬¦ï¼‰
                r'(\d{2,4}[-\s]\d{2,4}[-\s]\d{4})',
            ]
            for pattern in phone_patterns:
                match = re.search(pattern, text)
                if match:
                    phone = match.group(1).strip()
                    # æ¸…ç†ç”µè¯å·ç ä¸­çš„è¿å­—ç¬¦å’Œç©ºæ ¼
                    phone = re.sub(r'[-\s]', '', phone)
                    # éªŒè¯æ˜¯åˆç†çš„ç”µè¯å·ç é•¿åº¦
                    if len(phone) >= 10:
                        details['phone'] = phone
                        break
            
            # Address (åœ°å€) - æå–å®Œæ•´åœ°å€
            address_patterns = [
                r'Address[ï¼š:\s]*([^\n]{15,250}CN)',  # åŒ¹é…åˆ°CNç»“å°¾
                r'åœ°å€[ï¼š:\s]*([^\n]{15,200})',
                r'ä½æ‰€[ï¼š:\s]*([^\n]{15,200})',
                # ç›´æ¥åŒ¹é…å¸¦Buildingçš„åœ°å€æ ¼å¼
                r'(\d+,\s*Building\s+A\d[^\n]+?CN)',
            ]
            for pattern in address_patterns:
                match = re.search(pattern, text, re.IGNORECASE)
                if match:
                    addr = match.group(1).strip()
                    # æ¸…ç†åœ°å€ä¸­çš„å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ
                    addr = re.sub(r'\s+', ' ', addr)
                    # ç§»é™¤å¯èƒ½çš„å°¾éƒ¨åƒåœ¾
                    addr = re.sub(r'(CN).*$', r'\1', addr)
                    details['address'] = addr
                    break
            
            # Email
            email_match = re.search(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})', text)
            if email_match:
                details['email'] = email_match.group(1)
            
            # Fax
            fax_patterns = [
                r'FAX[ï¼š:\s]*(\d{10,15})',
                r'ãƒ•ã‚¡ãƒƒã‚¯ã‚¹[ï¼š:\s]*(\d{10,15})',
                r'ä¼ çœŸ[ï¼š:\s]*(\d{10,15})',
            ]
            for pattern in fax_patterns:
                match = re.search(pattern, text)
                if match:
                    details['fax'] = match.group(1).strip()
                    break
            
            # è´­ç‰©ä»£è¡¨å§“å (å¦‚æœæœ‰)
            rep_match = re.search(r'è³¼ç‰©ä»£è¡¨çš„å§“å[ï¼š:\s]*([^\n]{2,30})', text)
            if not rep_match:
                rep_match = re.search(r'ä»£è¡¨è€…æ°å[ï¼š:\s]*([^\n]{2,30})', text)
            if rep_match:
                details['representative'] = rep_match.group(1).strip()
            
            # åº—é“ºå (å•†åº—å)
            store_match = re.search(r'å•†åº—å[ï¼š:\s]*([^\n]{2,50})', text)
            if not store_match:
                store_match = re.search(r'åº—èˆ—å[ï¼š:\s]*([^\n]{2,50})', text)
            if store_match:
                details['store_name'] = store_match.group(1).strip()
            
            return details
        except Exception as e:
            print(f"æå–å–å®¶è¯¦æƒ…å¤±è´¥: {e}")
            return {}
    
    def _save_to_excel(self, products, sellers):
        """ä¿å­˜åˆ°Excel"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(self.save_directory, f"amazon_products_{timestamp}.xlsx")
        
        products_df = pd.DataFrame(products)
        sellers_df = pd.DataFrame(sellers) if sellers else pd.DataFrame()
        
        # ä¸­æ–‡åˆ—å
        product_mapping = {
            'asin': 'ASINç¼–å·',
            'title': 'äº§å“æ ‡é¢˜',
            'price': 'ä»·æ ¼',
            'rating': 'è¯„åˆ†',
            'url': 'äº§å“é“¾æ¥',
        }
        
        seller_mapping = {
            'seller_name': 'å–å®¶åç§°',
            'seller_url': 'å–å®¶é“¾æ¥',
            'phone': 'ç”µè¯å·ç ',
            'address': 'åœ°å€',
            'business_name': 'å…¬å¸åç§°',
            'product_title': 'å…³è”äº§å“',
            'product_price': 'äº§å“ä»·æ ¼',
            'product_url': 'äº§å“é“¾æ¥',
            'product_asin': 'äº§å“ASIN',
        }
        
        products_df = products_df.rename(columns=product_mapping)
        if not sellers_df.empty:
            sellers_df = sellers_df.rename(columns=seller_mapping)
        
        with pd.ExcelWriter(filename, engine='openpyxl') as writer:
            products_df.to_excel(writer, sheet_name='äº§å“ä¿¡æ¯', index=False)
            if not sellers_df.empty:
                sellers_df.to_excel(writer, sheet_name='å–å®¶ä¿¡æ¯', index=False)
        
        return filename
    
    def stop(self):
        self.is_searching = False


class SeleniumOnlyGUI:
    """çº¯Selenium GUI"""
    
    def __init__(self, root):
        self.root = root
        self.root.title("Amazon Japan å–å®¶ä¿¡æ¯æå–å·¥å…· - çº¯Seleniumç‰ˆ v5.0")
        self.root.geometry("800x650")
        
        self.scraper = SeleniumOnlyScraper()
        self.search_thread = None
        self.is_searching = False
        
        self.setup_gui()
    
    def setup_gui(self):
        main_frame = ttk.Frame(self.root, padding="20")
        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        ttk.Label(main_frame, text="ğŸš€ Amazon Japan å–å®¶ä¿¡æ¯æå–å·¥å…·",
                 font=('Arial', 16, 'bold')).grid(row=0, column=0, columnspan=2, pady=(0, 10))
        
        ttk.Label(main_frame, text="çº¯Seleniumç‰ˆ - ç»•è¿‡æ‰€æœ‰åçˆ¬è™«é™åˆ¶",
                 font=('Arial', 10), foreground='#0066cc').grid(row=1, column=0, columnspan=2, pady=(0, 20))
        
        config_frame = ttk.LabelFrame(main_frame, text="ğŸ” æœç´¢é…ç½®", padding="15")
        config_frame.grid(row=2, column=0, columnspan=2, sticky=(tk.W, tk.E), pady=(0, 15))
        
        ttk.Label(config_frame, text="å…³é”®è¯:").grid(row=0, column=0, sticky=tk.W, pady=5)
        self.keyword_var = tk.StringVar()
        ttk.Entry(config_frame, textvariable=self.keyword_var, width=40).grid(
            row=0, column=1, sticky=(tk.W, tk.E), padx=(10, 0), pady=5)
        
        ttk.Label(config_frame, text="é¡µæ•°:").grid(row=1, column=0, sticky=tk.W, pady=5)
        self.pages_var = tk.StringVar(value="3")
        ttk.Entry(config_frame, textvariable=self.pages_var, width=10).grid(
            row=1, column=1, sticky=tk.W, padx=(10, 0), pady=5)
        
        ttk.Label(config_frame, text="äº§å“æ•°:").grid(row=2, column=0, sticky=tk.W, pady=5)
        self.products_var = tk.StringVar(value="50")
        ttk.Entry(config_frame, textvariable=self.products_var, width=10).grid(
            row=2, column=1, sticky=tk.W, padx=(10, 0), pady=5)
        
        btn_frame = ttk.Frame(main_frame)
        btn_frame.grid(row=3, column=0, columnspan=2, pady=(0, 15))
        
        self.start_btn = ttk.Button(btn_frame, text="ğŸš€ å¼€å§‹æœç´¢", command=self.start_search)
        self.start_btn.grid(row=0, column=0, padx=(0, 10))
        
        self.stop_btn = ttk.Button(btn_frame, text="â¹ï¸ åœæ­¢", command=self.stop_search, state='disabled')
        self.stop_btn.grid(row=0, column=1, padx=(0, 10))
        
        ttk.Button(btn_frame, text="ğŸ“ æ‰“å¼€æ–‡ä»¶å¤¹", command=self.open_folder).grid(row=0, column=2)
        
        log_frame = ttk.LabelFrame(main_frame, text="ğŸ“ è¿è¡Œæ—¥å¿—", padding="15")
        log_frame.grid(row=4, column=0, columnspan=2, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        self.log_text = tk.Text(log_frame, height=22, width=70, font=('Consolas', 9))
        scrollbar = ttk.Scrollbar(log_frame, orient="vertical", command=self.log_text.yview)
        self.log_text.configure(yscrollcommand=scrollbar.set)
        
        self.log_text.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        scrollbar.grid(row=0, column=1, sticky=(tk.N, tk.S))
        
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        main_frame.columnconfigure(1, weight=1)
        main_frame.rowconfigure(4, weight=1)
        config_frame.columnconfigure(1, weight=1)
        log_frame.columnconfigure(0, weight=1)
        log_frame.rowconfigure(0, weight=1)
    
    def start_search(self):
        keyword = self.keyword_var.get().strip()
        if not keyword:
            messagebox.showerror("é”™è¯¯", "è¯·è¾“å…¥å…³é”®è¯")
            return
        
        try:
            max_pages = int(self.pages_var.get())
            max_products = int(self.products_var.get())
        except:
            messagebox.showerror("é”™è¯¯", "é¡µæ•°å’Œäº§å“æ•°å¿…é¡»æ˜¯æ•°å­—")
            return
        
        if self.is_searching:
            return
        
        self.is_searching = True
        self.start_btn.config(state='disabled')
        self.stop_btn.config(state='normal')
        self.log_text.delete(1.0, tk.END)
        
        self.search_thread = threading.Thread(
            target=self.search_worker,
            args=(keyword, max_pages, max_products),
            daemon=True
        )
        self.search_thread.start()
    
    def search_worker(self, keyword, max_pages, max_products):
        try:
            self.scraper.search_products(
                keyword=keyword,
                max_pages=max_pages,
                max_products=max_products,
                progress_callback=self.log_message,
                stop_flag=lambda: self.is_searching
            )
        except Exception as e:
            self.log_message(f"âŒ é”™è¯¯: {e}")
        finally:
            self.root.after(0, self.search_completed)
    
    def stop_search(self):
        self.is_searching = False
        self.scraper.stop()
        self.log_message("â¹ï¸ æ­£åœ¨åœæ­¢...")
    
    def search_completed(self):
        self.is_searching = False
        self.start_btn.config(state='normal')
        self.stop_btn.config(state='disabled')
    
    def log_message(self, message):
        def add():
            timestamp = datetime.now().strftime("%H:%M:%S")
            self.log_text.insert(tk.END, f"[{timestamp}] {message}\n")
            self.log_text.see(tk.END)
        self.root.after(0, add)
    
    def open_folder(self):
        import subprocess, platform
        path = os.path.abspath(self.scraper.save_directory)
        try:
            if platform.system() == "Windows":
                os.startfile(path)
            elif platform.system() == "Darwin":
                subprocess.run(["open", path])
            else:
                subprocess.run(["xdg-open", path])
        except Exception as e:
            messagebox.showerror("é”™è¯¯", f"æ— æ³•æ‰“å¼€: {e}")


def main():
    root = tk.Tk()
    app = SeleniumOnlyGUI(root)
    root.mainloop()


if __name__ == "__main__":
    main()

